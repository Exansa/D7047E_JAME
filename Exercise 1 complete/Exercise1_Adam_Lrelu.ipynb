{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
    "        self.Lrelu = nn.LeakyReLU()\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "            # Implement the forward function in the network\n",
    "            x = self.conv1(x)\n",
    "            x = self.Lrelu(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.Lrelu(x)\n",
    "            x = self.pool(x)\n",
    "            \n",
    "            x = torch.flatten(x, 1)\n",
    "\n",
    "            x = self.soft(self.fc1(x))\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_model_loss = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "\n",
    "            prediction = model.forward(data)\n",
    "\n",
    "            train_loss = criterion(prediction, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\n",
    "            f'\\rEpoch {epoch+1}, batch {i+1}/{len(train_loader)} - Loss: {train_loss}',\"\\n\"\n",
    "        )\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        writer.add_scalar(\"Loss/train_Adam_Lrelu\", train_loss, epoch)\n",
    "\n",
    "        # Validation\n",
    "        for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "            prediction = model.forward(data)\n",
    "            loss_val = criterion(prediction, labels)\n",
    "            valid_losses.append(loss_val)\n",
    "        print(f\"loss validation: {loss_val}\",\"\\n\")\n",
    "\n",
    "        if valid_losses[-1] < best_model_loss:\n",
    "            print(f\"\\t > Found a better model, {best_model_loss} -> {valid_losses[-1]}\")\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_model_loss = valid_losses[-1]\n",
    "\n",
    "        writer.add_scalar(\"Loss/validation_Adam_Lrelu\", loss_val, epoch)\n",
    "\n",
    "    print(f\"\\nBest model loss: {best_model_loss}\")\n",
    "    return best_model, train_losses, valid_losses\n",
    "\n",
    "def get_accuracy(network, loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        for x, (data, labels) in enumerate(loader):\n",
    "\n",
    "            prediction = network.forward(data)\n",
    "\n",
    "            for i in range(len(data)):\n",
    "\n",
    "                y_true.append(labels[i].item())\n",
    "                y_pred.append(torch.argmax(prediction[i]).item())\n",
    "                if y_true[i] == y_pred[i]:\n",
    "                    correct += 1        \n",
    "    \n",
    "            total += len(data)\n",
    "    \n",
    "        score = correct/total\n",
    "\n",
    "        accuracy = score\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1, batch 4000/4000 - Loss: 1.9696094989776611 \n",
      "\n",
      "loss validation: 1.9860728979110718 \n",
      "\n",
      "\t > Found a better model, 10 -> 1.9860728979110718\n",
      "Epoch 2, batch 4000/4000 - Loss: 2.1979033946990967 \n",
      "\n",
      "loss validation: 2.0322492122650146 \n",
      "\n",
      "Epoch 3, batch 4000/4000 - Loss: 2.12963604927063 \n",
      "\n",
      "loss validation: 2.166895866394043 \n",
      "\n",
      "Epoch 4, batch 4000/4000 - Loss: 2.034350872039795 \n",
      "\n",
      "loss validation: 1.8388944864273071 \n",
      "\n",
      "\t > Found a better model, 1.9860728979110718 -> 1.8388944864273071\n",
      "Epoch 5, batch 4000/4000 - Loss: 1.9600419998168945 \n",
      "\n",
      "loss validation: 1.995248556137085 \n",
      "\n",
      "Epoch 6, batch 4000/4000 - Loss: 1.9825375080108643 \n",
      "\n",
      "loss validation: 2.138272523880005 \n",
      "\n",
      "Epoch 7, batch 4000/4000 - Loss: 2.020216464996338 \n",
      "\n",
      "loss validation: 2.00547456741333 \n",
      "\n",
      "Epoch 8, batch 4000/4000 - Loss: 2.1127102375030518 \n",
      "\n",
      "loss validation: 1.8540372848510742 \n",
      "\n",
      "Epoch 9, batch 4000/4000 - Loss: 1.9877088069915771 \n",
      "\n",
      "loss validation: 1.7689176797866821 \n",
      "\n",
      "\t > Found a better model, 1.8388944864273071 -> 1.7689176797866821\n",
      "Epoch 10, batch 4000/4000 - Loss: 2.162384510040283 \n",
      "\n",
      "loss validation: 2.0492053031921387 \n",
      "\n",
      "\n",
      "Best model loss: 1.7689176797866821\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "\n",
    "validset, trainset = torch.utils.data.random_split(trainset, [10000, 40000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset = torchvision.datasets.CIFAR10('./data', train=True, download=True)\n",
    "\n",
    "# Load our network\n",
    "model = Net()\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model, train_loss, valid_loss = train_model(model, criterion, optimizer, trainloader, validloader, EPOCHS)\n",
    "\n",
    "# Test the model\n",
    "test_acc = get_accuracy(trained_model, testloader)\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam + LReLU 30 March - 09:40 am\n",
    "Test results: 0.6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 10)\n",
    "        self.Lrelu = nn.LeakyReLU()\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "            # Implement the forward function in the network\n",
    "            x = self.conv1(x)\n",
    "            x = self.Lrelu(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.Lrelu(x)\n",
    "            x = self.pool(x)\n",
    "            \n",
    "            x = torch.flatten(x, 1)\n",
    "\n",
    "            x = self.soft(self.fc1(x))\n",
    "            \n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_model_loss = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "\n",
    "            prediction = model.forward(data)\n",
    "\n",
    "            train_loss = criterion(prediction, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print(\n",
    "            f'\\rEpoch {epoch+1}, batch {i+1}/{len(train_loader)} - Loss: {train_loss}',\"\\n\"\n",
    "        )\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "        # Validation\n",
    "        for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "            prediction = model.forward(data)\n",
    "            loss_val = criterion(prediction, labels)\n",
    "            valid_losses.append(loss_val)\n",
    "        print(f\"loss validation: {loss_val}\",\"\\n\")\n",
    "\n",
    "        if valid_losses[-1] < best_model_loss:\n",
    "            print(f\"\\t > Found a better model, {best_model_loss} -> {valid_losses[-1]}\")\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_model_loss = valid_losses[-1]\n",
    "\n",
    "        writer.add_scalar(\"Loss/validation\", loss_val, epoch)\n",
    "\n",
    "    print(f\"\\nBest model loss: {best_model_loss}\")\n",
    "    return best_model, train_losses, valid_losses\n",
    "\n",
    "def get_accuracy(network, loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        for x, (data, labels) in enumerate(loader):\n",
    "\n",
    "            prediction = network.forward(data)\n",
    "\n",
    "            for i in range(len(data)):\n",
    "\n",
    "                y_true.append(labels[i].item())\n",
    "                y_pred.append(torch.argmax(prediction[i]).item())\n",
    "                if y_true[i] == y_pred[i]:\n",
    "                    correct += 1        \n",
    "    \n",
    "            total += len(data)\n",
    "    \n",
    "        score = correct/total\n",
    "\n",
    "        accuracy = score\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1, batch 4000/4000 - Loss: 2.257594585418701loss validation: 2.2037041187286377 \n",
      "\n",
      "\t > Found a better model, 10 -> 2.2037041187286377\n",
      "Epoch 2, batch 4000/4000 - Loss: 2.0587565898895264loss validation: 2.255225658416748 \n",
      "\n",
      "Epoch 3, batch 4000/4000 - Loss: 2.139312744140625loss validation: 2.0378122329711914 \n",
      "\n",
      "\t > Found a better model, 2.2037041187286377 -> 2.0378122329711914\n",
      "Epoch 4, batch 4000/4000 - Loss: 2.263286828994751loss validation: 1.9436057806015015 \n",
      "\n",
      "\t > Found a better model, 2.0378122329711914 -> 1.9436057806015015\n",
      "Epoch 5, batch 4000/4000 - Loss: 1.8800060749053955loss validation: 1.9040483236312866 \n",
      "\n",
      "\t > Found a better model, 1.9436057806015015 -> 1.9040483236312866\n",
      "Epoch 6, batch 4000/4000 - Loss: 1.923203706741333loss validation: 2.3047728538513184 \n",
      "\n",
      "Epoch 7, batch 4000/4000 - Loss: 1.7366329431533813loss validation: 1.9874076843261719 \n",
      "\n",
      "Epoch 8, batch 4000/4000 - Loss: 1.9973331689834595loss validation: 1.834277868270874 \n",
      "\n",
      "\t > Found a better model, 1.9040483236312866 -> 1.834277868270874\n",
      "Epoch 9, batch 4000/4000 - Loss: 1.9115970134735107loss validation: 1.9822213649749756 \n",
      "\n",
      "Epoch 10, batch 4000/4000 - Loss: 2.1601881980895996loss validation: 2.1371469497680664 \n",
      "\n",
      "\n",
      "Best model loss: 1.834277868270874\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "\n",
    "validset, trainset = torch.utils.data.random_split(trainset, [10000, 40000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "\n",
    "# Dataset\n",
    "dataset = torchvision.datasets.CIFAR10('./data', train=True, download=True)\n",
    "\n",
    "# Load our network\n",
    "model = Net()\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model, train_loss, valid_loss = train_model(model, criterion, optimizer, trainloader, validloader, EPOCHS)\n",
    "\n",
    "# Test the model\n",
    "test_acc = get_accuracy(trained_model, testloader)\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD + LReLU\n",
    "Results:\n",
    "# Adam + LReLU\n",
    "Results:\n",
    "# SGD + Tanh\n",
    "Results:\n",
    "# ADAM + Tanh\n",
    "Results:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

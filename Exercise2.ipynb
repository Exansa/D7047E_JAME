{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "                super(Net, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "                self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "\n",
    "                self.fc1 = nn.Linear(4*4*64, 512)\n",
    "                self.fc2 = nn.Linear(512, 256)\n",
    "                self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "                self.pool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "                self.drop1 = nn.Dropout(0.25) # Try 0.5\n",
    "                self.drop2 = nn.Dropout(0.50)\n",
    "\n",
    "        def forward(self, x):\n",
    "                x = F.relu(self.conv1(x))\n",
    "                x = self.pool(x)\n",
    "                x = self.drop1(x)\n",
    "                x = F.relu(self.conv2(x))\n",
    "                x = self.pool(x)\n",
    "                x = x.reshape(-1, 1024)\n",
    "                x = F.relu(self.fc1(x))\n",
    "                x = self.drop2(x)\n",
    "                x = F.relu(self.fc2(x))\n",
    "                x = self.fc3(x)\n",
    "                return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimixer, train_loader, val_loader, num_epochs):\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_model_loss = 10\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        for i, (data, labels) in enumerate(train_loader):\n",
    "      \n",
    "            prediction = model.forward(data)\n",
    "\n",
    "            train_loss = criterion(prediction, labels)\n",
    "\n",
    "            train_loss.backward()\n",
    "\n",
    "            optimixer.step()\n",
    "\n",
    "            optimixer.zero_grad()\n",
    "        print(\n",
    "            f'\\rEpoch {epoch+1}, batch {i+1}/{len(train_loader)} - Loss: {train_loss}',\"\\n\"\n",
    "        )\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
    "\n",
    "        # Validation\n",
    "        for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "            prediction = model.forward(data)\n",
    "            loss_val = criterion(prediction, labels)\n",
    "            valid_losses.append(loss_val)\n",
    "        print(f\"loss validation: {loss_val}\",\"\\n\")\n",
    "\n",
    "        if valid_losses[-1] < best_model_loss:\n",
    "            print(f\"\\t > Found a better model, {best_model_loss} -> {valid_losses[-1]}\")\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_model_loss = valid_losses[-1]\n",
    "\n",
    "        writer.add_scalar(\"Loss/validation\", loss_val, epoch)\n",
    "\n",
    "    print(f\"\\nBest model loss: {best_model_loss}\")\n",
    "    return best_model, train_losses, valid_losses\n",
    "\n",
    "def get_accuracy(network, loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        for x, (data, labels) in enumerate(loader):\n",
    "\n",
    "            prediction = network.forward(data)\n",
    "\n",
    "            for i in range(len(data)):\n",
    "\n",
    "                y_true.append(labels[i].item())\n",
    "                y_pred.append(torch.argmax(prediction[i]).item())\n",
    "                if y_true[i] == y_pred[i]:\n",
    "                    correct += 1        \n",
    "    \n",
    "            total += float(len(data))\n",
    "    \n",
    "        score = correct/total\n",
    "\n",
    "        accuracy = score\n",
    "\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, batch 40/40 - Loss: 0.3381681740283966 \n",
      "\n",
      "loss validation: 0.2780453562736511 \n",
      "\n",
      "\t > Found a better model, 10 -> 0.2780453562736511\n",
      "Epoch 2, batch 40/40 - Loss: 0.15382182598114014 \n",
      "\n",
      "loss validation: 0.1875322312116623 \n",
      "\n",
      "\t > Found a better model, 0.2780453562736511 -> 0.1875322312116623\n",
      "Epoch 3, batch 40/40 - Loss: 0.09274882078170776 \n",
      "\n",
      "loss validation: 0.10112753510475159 \n",
      "\n",
      "\t > Found a better model, 0.1875322312116623 -> 0.10112753510475159\n",
      "Epoch 4, batch 40/40 - Loss: 0.08749064803123474 \n",
      "\n",
      "loss validation: 0.10950310528278351 \n",
      "\n",
      "Epoch 5, batch 40/40 - Loss: 0.06577182561159134 \n",
      "\n",
      "loss validation: 0.07207788527011871 \n",
      "\n",
      "\t > Found a better model, 0.10112753510475159 -> 0.07207788527011871\n",
      "Epoch 6, batch 40/40 - Loss: 0.044530414044857025 \n",
      "\n",
      "loss validation: 0.04476452246308327 \n",
      "\n",
      "\t > Found a better model, 0.07207788527011871 -> 0.04476452246308327\n",
      "Epoch 7, batch 40/40 - Loss: 0.04495922848582268 \n",
      "\n",
      "loss validation: 0.052519895136356354 \n",
      "\n",
      "Epoch 8, batch 40/40 - Loss: 0.041285980492830276 \n",
      "\n",
      "loss validation: 0.059463780373334885 \n",
      "\n",
      "Epoch 9, batch 40/40 - Loss: 0.042120978236198425 \n",
      "\n",
      "loss validation: 0.06037164106965065 \n",
      "\n",
      "Epoch 10, batch 40/40 - Loss: 0.049574725329875946 \n",
      "\n",
      "loss validation: 0.04778053238987923 \n",
      "\n",
      "\n",
      "Best model loss: 0.04476452246308327\n",
      "0.981\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,download=True, transform=transform)\n",
    "\n",
    "validset, trainset = torch.utils.data.random_split(trainset, [20000, 40000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "trained_model, train_loss, valid_loss = train_model(model, criterion, optimizer, trainloader, validloader, EPOCHS)\n",
    "\n",
    "test_acc = get_accuracy(trained_model, testloader)\n",
    "print(test_acc)\n",
    "writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try network on SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\train_32x32.mat\n",
      "0.183\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)), # The 3 channels becomes between -1 and 1. Formula: (pixelvalue - mean)/std\n",
    "                                transforms.Resize(28),\n",
    "                                transforms.Grayscale(num_output_channels=1)])\n",
    "\n",
    "dataset = torchvision.datasets.SVHN(root='./data',download=True,transform=transform)\n",
    "\n",
    "testset, validset, trainset = torch.utils.data.random_split(dataset, [10000,12000,51257])\n",
    "\n",
    "trainloader_svhn = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "validloader_svhn = torch.utils.data.DataLoader(validset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "testloader_svhn = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,shuffle=False)\n",
    "\n",
    "# Test the model\n",
    "test_acc = get_accuracy(trained_model, testloader_svhn)\n",
    "print(test_acc)\n",
    "writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning (fine-tune): MNIST -> SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, batch 52/52 - Loss: 1.1255439519882202 \n",
      "\n",
      "loss validation: 1.105072259902954 \n",
      "\n",
      "\t > Found a better model, 10 -> 1.105072259902954\n",
      "Epoch 2, batch 52/52 - Loss: 0.8605552315711975 \n",
      "\n",
      "loss validation: 0.912015974521637 \n",
      "\n",
      "\t > Found a better model, 1.105072259902954 -> 0.912015974521637\n",
      "Epoch 3, batch 52/52 - Loss: 0.8035498261451721 \n",
      "\n",
      "loss validation: 0.7923974394798279 \n",
      "\n",
      "\t > Found a better model, 0.912015974521637 -> 0.7923974394798279\n",
      "Epoch 4, batch 52/52 - Loss: 0.7846595048904419 \n",
      "\n",
      "loss validation: 0.7232319712638855 \n",
      "\n",
      "\t > Found a better model, 0.7923974394798279 -> 0.7232319712638855\n",
      "Epoch 5, batch 52/52 - Loss: 0.6200501918792725 \n",
      "\n",
      "loss validation: 0.7335819005966187 \n",
      "\n",
      "\n",
      "Best model loss: 0.7232319712638855\n",
      "0.773\n"
     ]
    }
   ],
   "source": [
    "model_finetune = trained_model\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 5\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimixer\n",
    "optimizer = torch.optim.Adam(model_finetune.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model_finetuned, train_loss, valid_loss = train_model(model_finetune, criterion, optimizer, trainloader_svhn, validloader_svhn, EPOCHS)\n",
    "\n",
    "# Test the model\n",
    "test_acc = get_accuracy(trained_model_finetuned, testloader_svhn)\n",
    "print(test_acc)\n",
    "writer.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning (feature extraction): MNIST -> SVHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, batch 52/52 - Loss: 0.7887284755706787 \n",
      "\n",
      "loss validation: 0.593209981918335 \n",
      "\n",
      "\t > Found a better model, 10 -> 0.593209981918335\n",
      "Epoch 2, batch 52/52 - Loss: 0.5977726578712463 \n",
      "\n",
      "loss validation: 0.7530398368835449 \n",
      "\n",
      "Epoch 3, batch 52/52 - Loss: 0.5757005214691162 \n",
      "\n",
      "loss validation: 0.6883167624473572 \n",
      "\n",
      "Epoch 4, batch 52/52 - Loss: 0.4649699032306671 \n",
      "\n",
      "loss validation: 0.725853443145752 \n",
      "\n",
      "Epoch 5, batch 52/52 - Loss: 0.6794815063476562 \n",
      "\n",
      "loss validation: 0.6937739849090576 \n",
      "\n",
      "\n",
      "Best model loss: 0.593209981918335\n",
      "0.793\n"
     ]
    }
   ],
   "source": [
    "model_featext = trained_model\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 5\n",
    "\n",
    "# Freeze all layers except the last few layers\n",
    "for name, param in model_featext.named_parameters():\n",
    "    if \"fc3\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define our optimixer\n",
    "optimizer = torch.optim.Adam(model_featext.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "# Train the model\n",
    "trained_model_featexted, train_loss, valid_loss = train_model(model_featext, criterion, optimizer, trainloader_svhn, validloader_svhn, EPOCHS)\n",
    "\n",
    "# Test the model\n",
    "test_acc = get_accuracy(trained_model_featexted, testloader_svhn)\n",
    "print(test_acc)\n",
    "writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b092dd6cd17ec779f3bae5064f9d72da31268a5c4a5fd51a6f11e9df3477f045"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

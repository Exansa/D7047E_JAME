{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "1.1 Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True values\n",
    "g = np.array([0,1,0])\n",
    "# Predicted values\n",
    "y = np.array([0.25,0.6,0.15])\n",
    "\n",
    "# Cross-Entropy Loss (or Logistic Loss)\n",
    "H = 0\n",
    "for i in range(y.size):\n",
    "    H += - np.dot(g[i],math.log(y[i],10))\n",
    "\n",
    "# Mean Squared Error-Loss\n",
    "MSE = 0\n",
    "for i in range(y.size):\n",
    "    MSE += np.square(y[i]-g[i])\n",
    "MSE = 1/y.size * MSE\n",
    "\n",
    "# Hinge Loss (or SVM Loss)\n",
    "SVM = 0\n",
    "for i in range(y.size): \n",
    "    if i != 1:\n",
    "        SVM += max(0,y[i]-y[1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22184874961635637"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08166666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2000000000000002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-entropy loss is zero if the predicted value match the true one and infinite if they don't match at all. When the prediction is good the weights are barely changed, whereas they change a lot if the prediction is bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
